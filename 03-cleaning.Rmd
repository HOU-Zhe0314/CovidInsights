# Data transformation

## Hospital Visits Data
The estimation of "the percentage of COVID-related doctor's vistis" works as follows:
For a fixed time t and location i, there are counts of Covid-like symptoms, Flu-like symptoms, Mixed symptoms, Clealy-Flu symptoms, and total counts of visits. Then estimate the percentage of COVID-like symptoms as:

**100 * (CovidLike + FluLike + Mixed - ClearlyFlu) / total**

To enhance variablility, a local linear regression filter with a Gaussian kernel is applied, the bandwidth is set to 7 to cover a rolling 7-day window.
```{r}
#install.packages("covidcast")
library(covidcast)
library(tidyverse)
library(patchwork)
```
```{r}
doctor_visit_data_raw <- covidcast_signal("doctor-visits", "smoothed_cli", start_day = "2020-02-01", end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
```

However, after smoothing the data, the standard error estimate is claimed to be inaccurate any more, so we just removed the column of standard errors. According to the API, only three columns are meaningful for analysis, and all the other columns consist of the same value all the way through, so we just removed them. 
```{r}
doctor_visit_data <- doctor_visit_data_raw[c('geo_value','time_value','value')]
```
Hence, the resulting variables in the dataset are: 'location', 'time', 'smoothed estimated percentage of COVID-related doctor's vistis'.

## Hospital Admissions Data
```{r, message=F, warning=F}
hospital_data_raw <- covidcast_signal("hospital-admissions", "smoothed_covid19_from_claims", start_day = "2020-02-01", end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
```
This data went through the same smoothing adjustment as above. So for the same reason, we removed the columns associated with standard error and all other columns that consist of the same value all the way through. 
```{r}
hospital_data <- hospital_data_raw[c('geo_value','time_value','value')]
```
The resulting variables are: 'location', 'time', 'smoothed estimated percentage of new hospital admissions related to COVID'. 

## Restaurant Visit Data & Bar Visit Data
Same reason as above. The resulting variables are: 'location', 'time', 'visits to restaurants (or bars) by users of the 'SafeGraph' app, per 100000 population'.
```{r,warning=F}
restaurant_data_raw <- covidcast_signal("safegraph", "restaurants_visit_prop", start_day = "2020-02-01", end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
restaurant_data <- restaurant_data_raw[c('geo_value','time_value','value')]
```
```{r,warning=F}
bar_data_raw <- covidcast_signal("safegraph", "bars_visit_prop", start_day = "2020-02-01", end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
bar_data <- bar_data_raw[c('geo_value','time_value','value')]
```


## Survey about Depression, Isolation, and Financial Difficulty
Same reason as above. The resulting variables are: 'location', 'time', 'percentage of people who expressed depression (or isolation, or financial difficulty)'
```{r}
depressed_raw <- covidcast_signal("fb-survey", "smoothed_wdepressed_5d", start_day = "2020-09-08",
                         end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
depressed <- depressed_raw[c('geo_value','time_value','value')]
isolated_raw <- covidcast_signal("fb-survey", "smoothed_wfelt_isolated_5d", start_day = "2020-09-08",
                         end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
isolated <- depressed_raw[c('geo_value','time_value','value')]
ill_raw <- covidcast_signal("fb-survey", "smoothed_wworried_become_ill", start_day = "2020-09-08",
                         end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
ill <- depressed_raw[c('geo_value','time_value','value')]
```

## Google Search Trends symptems data
This data measured in arbitrary units that are normalized for overall search users in the region and then scaled by the maximum value of the normalized popularity in a specific region and a specific time range. In this data, large numebrs stand for increased releative popularity of symptom-related searches.
The resulting variables are: 'location', 'time', 'sum of Google search volume for anosmia and ageusia related searches'.
```{r}
google_data_raw <- covidcast_signal("google-symptoms", "sum_anosmia_ageusia_raw_search", start_day = "2020-02-01", end_day = "2021-02-01", geo_type='state',geo_values=c('ny','ca','tx','co','hi','wa','ks','va','mo'))
google_data <- google_data_raw[c('geo_value','time_value','value')]
```